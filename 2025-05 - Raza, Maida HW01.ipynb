{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776bd291",
   "metadata": {},
   "source": [
    "# HW01 - Test and Train Split; K-Nearest Neighbors\n",
    "\n",
    "Name: Maida Raza\n",
    "\n",
    "Tufts University\n",
    "\n",
    "CS 135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0432cb0",
   "metadata": {},
   "source": [
    "# Q1 - Test and Train Split\n",
    "\n",
    "(10 pts.) The first part of the code asks you to write a function to split data into a training set and a testing set (a very common task in ML). Your code will use basic NumPy array indexing and random number generation to take an input array containing L instances of F-dimensional data, and divide it into two mutually exclusive arrays of size M (for training) and N (for testing). As part of its input, the function takes parameter frac_test, specifying the overall fraction\n",
    "of the data-set to use for testing purposes. It will use this fraction to determine the size N, rounding up to the nearest whole number: N = ⌈frac_test ∗ L⌉ The function will also use NumPy functions like shuffle or permutation for doing random sampling of the data, so that the test/train instances are uniformly selected from the data-set: https://numpy.org/doc/stable/reference/random/legacy.html \n",
    "\n",
    "(Note that this links to a library that has been generally replaced by something a bit newer in the latest version of NumPy, but is still supported. Your code will function correctly if you use the legacy version, or the newer NumPy features.) Furthermore, we want the results of the function to be reproducible, for scientific purposes. That means that there should be a way to specify a source of randomness (a seed) such that it is possible to duplicate any random selection. In NumPy, this is generally handled by using a RandomState instance, or via an integer seed. See the linked discussion from the source code comments for insight into using such seeds in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e756b616-ee37-49be-9b0e-4b9daeb44c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7]), array([7]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def split_into_train_and_test(x_all_LF, frac_test=0.5, random_state=None): #frac_test allocates half of the data to test and half to training. If random_state has a number to it, then the split is reproducible\n",
    "    L = x_all_LF.shape[0] #shape[0] to get the number of rows, shape(1) to get the number of columns\n",
    "    N = int(np.ceil(frac_test*L))\n",
    "\n",
    "    if isinstance(random_state, np.random.RandomState):\n",
    "        rng = random_state\n",
    "    else:\n",
    "        rng = np.random.RandomState(seed=random_state)\n",
    "\n",
    "    permuted_index = rng.permutation(L)\n",
    "    test_array = permuted_index[:N]\n",
    "    train_array = permuted_index[N:]\n",
    "\n",
    "    x_test = x_all_LF[test_array]\n",
    "    x_train = x_all_LF[train_array]\n",
    "\n",
    "    return np.array(x_test), np.array(x_train)\n",
    "    \n",
    "data = np.array([[2,3,4],[9,7,0]])\n",
    "\n",
    "rows = np.random.randint(0,2, size = 2)\n",
    "cols = np.random.randint(0,3, size = 2)\n",
    "\n",
    "split_into_train_and_test(data[rows, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b9a067-4de9-4af7-a10e-200534ba072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3, 4]]),\n",
       " array([[ 9, 10, 11, 12],\n",
       "        [ 5,  6,  7,  8]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_into_train_and_test(x_all_LF, frac_test=0.4, random_state=None):\n",
    "    L = x_all_LF.shape[0] #when it says L instances, its actually syaing the number of rows\n",
    "    N = int(np.ceil(frac_test*L))\n",
    "    print(N)\n",
    "    \n",
    "    shuffle_indices = np.random.permutation(L) # we are shuffling the rows\n",
    "    test_indices = shuffle_indices[:N]\n",
    "    train_indices = shuffle_indices[N:]\n",
    "\n",
    "    test_data = x_all_LF[test_indices]\n",
    "    train_data = x_all_LF[train_indices]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "data = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "\n",
    "split_into_train_and_test(data, frac_test=0.4, random_state=43)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feed99c",
   "metadata": {},
   "source": [
    "# Q2 - K-Nearest Neighbours\n",
    "\n",
    "(10 pts.) The other function you are to complete finds nearest neighbors of given data instances. That is, given a set of F-dimensional data of size N, and Q query instances (also F-dimensional), we want to compute the K closest vectors found in the data, for some integer value K, and for each query instance (for a total of Q × K neighbors).\n",
    "\n",
    "Your function will take in a data-set (a 2-dimensional array of size N × F) and a query-set (a 2-dimensional array of size Q×F), and return a 3-dimensional array (of size Q×K ×F), where each row (indexed by Q) consists of the K nearest neighbors of the corresponding query vector. These neighbors should appear in order, closest to least-close.\n",
    "\n",
    "Notes: it is possible that there will be ties among neighbors. If this occurs, such ties can be broken however you like (randomly or not). Again, be sure that your code uses only basic Python and functions from NumPy. Do not call functions from libraries like sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edad330-6e20-401b-bf87-d62fb6e6720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5,  7]],\n",
       "\n",
       "       [[15, 11]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input will be query (QxF) and data (NxF)\n",
    "#output will be (QxKxF)\n",
    "#the smaller the distance, the closer two vectors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calc_k_nearest_neighbors(data_NF, query_QF, K=1):\n",
    "    data_NF = np.array(data_NF)\n",
    "    query_QF = np.array(query_QF)\n",
    "    \n",
    "    all_neighbors = [] # we will store the distance between two points here\n",
    "    \n",
    "    for q in range(len(query_QF)):\n",
    "        distance = []\n",
    "        for d in range(len(data_NF)):\n",
    "            temp_distance = np.sum(np.square(data_NF[d] - query_QF[q]))\n",
    "            distance.append((d, temp_distance))\n",
    "\n",
    "        distance.sort(key = lambda x: x[1])\n",
    "        k_nearest = distance[:K]\n",
    "\n",
    "        neighbors_for_q = []\n",
    "        for item in k_nearest:\n",
    "            indice = item[0]\n",
    "            neighbors_for_q.append(data_NF[indice])\n",
    "                \n",
    "        all_neighbors.append(neighbors_for_q)\n",
    "    return np.array(all_neighbors)\n",
    "        #from the tuples, get \n",
    "\n",
    "data = [[2,3],[5,7],[0,7],[15,11]]\n",
    "\n",
    "query = [[8,10],[11,13]]\n",
    "\n",
    "calc_k_nearest_neighbors(data, query, K=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml135_env_sp21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
